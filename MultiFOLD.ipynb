{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from skimage import img_as_ubyte\n",
    "\n",
    "from Restormer.basicsr.models.archs.restormer_arch import Restormer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyQt5.QtWidgets import (QMainWindow, QGroupBox, QAction, QStyle, QWidget, QVBoxLayout, QHBoxLayout, QPushButton, QLabel, QTextEdit, QFileDialog, QApplication, QStatusBar,\n",
    "                             QComboBox, QDesktopWidget, QMessageBox, QSizePolicy, QScrollArea, QSlider, QGridLayout, QCheckBox)\n",
    "from PyQt5.QtGui import QPixmap, QImage, QPalette, QColor, QPainter, QFont\n",
    "from PyQt5.QtCore import Qt, QDateTime, QThread, pyqtSignal\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import speech_recognition as sr\n",
    "from pdf2image import convert_from_path\n",
    "from docx import Document\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pyaudio\n",
    "import wave\n",
    "import re\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "# os.environ[\"QT_QPA_PLATFORM\"] = \"xcb\"\n",
    "\n",
    "class RecordingThread(QThread):\n",
    "    \"\"\"Thread to handle audio recording without blocking the GUI\"\"\"\n",
    "    finished = pyqtSignal(str, str)  # Will emit transcription text and filepath\n",
    "    \n",
    "    def __init__(self, filename):\n",
    "        super().__init__()\n",
    "        self.filename = filename\n",
    "        self.running = True\n",
    "        \n",
    "    def run(self):\n",
    "        # Audio recording parameters\n",
    "        FORMAT = pyaudio.paInt16\n",
    "        CHANNELS = 1\n",
    "        RATE = 44100\n",
    "        CHUNK = 1024\n",
    "        \n",
    "        audio = pyaudio.PyAudio()\n",
    "        \n",
    "        # Start recording\n",
    "        stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                            rate=RATE, input=True,\n",
    "                            frames_per_buffer=CHUNK)\n",
    "        \n",
    "        frames = []\n",
    "        \n",
    "        while self.running:\n",
    "            data = stream.read(CHUNK)\n",
    "            frames.append(data)\n",
    "        \n",
    "        # Stop recording\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        audio.terminate()\n",
    "        \n",
    "        # Save the recording\n",
    "        wf = wave.open(self.filename, 'wb')\n",
    "        wf.setnchannels(CHANNELS)\n",
    "        wf.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "        wf.setframerate(RATE)\n",
    "        wf.writeframes(b''.join(frames))\n",
    "        wf.close()\n",
    "        \n",
    "        # Transcribe\n",
    "        recognizer = sr.Recognizer()\n",
    "        with sr.AudioFile(self.filename) as source:\n",
    "            audio_data = recognizer.record(source)\n",
    "            try:\n",
    "                text = recognizer.recognize_google(audio_data)\n",
    "                self.finished.emit(text, self.filename)\n",
    "            except sr.UnknownValueError:\n",
    "                self.finished.emit(\"Speech recognition could not understand audio\", self.filename)\n",
    "            except sr.RequestError as e:\n",
    "                self.finished.emit(f\"Could not request results; {e}\", self.filename)\n",
    "        \n",
    "    def stop(self):\n",
    "        self.running = False\n",
    "\n",
    "\n",
    "class MultiFOLD(QMainWindow):  # Changed to QMainWindow for proper menu bar\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.init_ui()\n",
    "\n",
    "    def init_ui(self):\n",
    "        ################################# WINDOW SETUP #################################\n",
    "        # Get screen size (primary screen)\n",
    "        screen_geometry = QDesktopWidget().screenGeometry()\n",
    "\n",
    "        # Set window title and size relative to screen size\n",
    "        self.setWindowTitle('MultiFOLD - Document Analysis and Correction')\n",
    "\n",
    "        # Calculate window size (80% of screen width and height)\n",
    "        window_width = int(screen_geometry.width() * 0.8)\n",
    "        window_height = int(screen_geometry.height() * 0.8)\n",
    "\n",
    "        # Ensure the window fits within the screen bounds\n",
    "        window_width = min(window_width, screen_geometry.width())\n",
    "        window_height = min(window_height, screen_geometry.height())\n",
    "\n",
    "        # (width, height)\n",
    "        self.setGeometry(100, 100, window_width, window_height)\n",
    "\n",
    "        ################################# CREATE MENU BAR #################################\n",
    "        self.create_menu_bar()\n",
    "\n",
    "        ################################# STATUS BAR #################################\n",
    "        self.statusBar = QStatusBar()\n",
    "        self.setStatusBar(self.statusBar)\n",
    "        self.statusBar.showMessage(\"Ready\")\n",
    "\n",
    "        ################################# CENTRAL WIDGET #################################\n",
    "        central_widget = QWidget()\n",
    "        self.setCentralWidget(central_widget)\n",
    "        main_layout = QHBoxLayout(central_widget)\n",
    "\n",
    "        ################################# DIRECTORIES FOR RECORDING #################################\n",
    "        # Initialize directory attributes first\n",
    "        self.recordings_dir = \"recordings\"\n",
    "        self.transcriptions_dir = \"transcriptions\"\n",
    "        \n",
    "        # Create directories if they don't exist\n",
    "        for directory in [self.recordings_dir, self.transcriptions_dir]:\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "        \n",
    "        # Initialize other attributes\n",
    "        self.recording_thread = None\n",
    "        self.last_transcription = \"\"\n",
    "        self.current_audio_file = \"\"\n",
    "        self.current_timestamp = \"\"\n",
    "        \n",
    "        ################################# IMAGE VIEWING VARIABLES #################################\n",
    "        # Minimum zoom level (percentage)\n",
    "        self.min_zoom = 10    \n",
    "        # Maximum zoom level (percentage) \n",
    "        self.max_zoom = 300  \n",
    "        # Current zoom level (percentage)   \n",
    "        self.current_zoom = 100 \n",
    "        # Zoom step percentage \n",
    "        self.zoom_step = 5\n",
    "        \n",
    "        # Initialize variables\n",
    "        self.image_file = None  # Store the loaded image\n",
    "        self.original_image = None  # Store the original image before Restormer\n",
    "        self.restormer_applied = False  # Track if Restormer is applied\n",
    "        self.start_time = None  # For timer\n",
    "        self.end_time = None    # For timer\n",
    "\n",
    "        ################################# LEFT PANEL #################################\n",
    "        left_panel = QVBoxLayout()\n",
    "        \n",
    "        # Document Controls Group\n",
    "        doc_controls_group = QGroupBox(\"Document Controls\")\n",
    "        doc_controls_layout = QVBoxLayout()\n",
    "        \n",
    "        # Document Processing Options\n",
    "        processing_options_group = QGroupBox(\"Processing Options\")\n",
    "        processing_options_layout = QVBoxLayout()\n",
    "        \n",
    "        # Restormer toggle button\n",
    "        restormer_layout = QHBoxLayout()\n",
    "        restormer_label = QLabel(\"Image Restoration:\")\n",
    "        self.restormer_toggle = QCheckBox(\"Apply Restormer\")\n",
    "        self.restormer_toggle.setToolTip(\"Apply Restormer image restoration model to enhance document quality\")\n",
    "        self.restormer_toggle.stateChanged.connect(self.toggle_restormer)\n",
    "        restormer_layout.addWidget(restormer_label)\n",
    "        restormer_layout.addWidget(self.restormer_toggle)\n",
    "        \n",
    "        # Add to processing options\n",
    "        processing_options_layout.addLayout(restormer_layout)\n",
    "        processing_options_group.setLayout(processing_options_layout)\n",
    "        \n",
    "        # Document Viewer\n",
    "        image_viewer_group = QGroupBox(\"Document Viewer\")\n",
    "        image_viewer_layout = QVBoxLayout()\n",
    "        \n",
    "        # Scroll area for the image\n",
    "        self.scroll_area = QScrollArea()\n",
    "        self.scroll_area.setWidgetResizable(True)\n",
    "        self.scroll_area.setHorizontalScrollBarPolicy(Qt.ScrollBarAsNeeded)\n",
    "        self.scroll_area.setVerticalScrollBarPolicy(Qt.ScrollBarAsNeeded)\n",
    "        \n",
    "        # Create image label\n",
    "        self.image = QLabel()\n",
    "        self.image_height = 600  # Default height\n",
    "        self.image_width = 800   # Default width\n",
    "        self.image.setAlignment(Qt.AlignCenter)\n",
    "        self.image.setSizePolicy(QSizePolicy.Ignored, QSizePolicy.Ignored)\n",
    "        self.image.setScaledContents(True)\n",
    "        \n",
    "        # Add image label to scroll area\n",
    "        self.scroll_area.setWidget(self.image)\n",
    "        \n",
    "        # Enable mouse wheel events for the scroll area\n",
    "        self.scroll_area.setMouseTracking(True)\n",
    "        self.scroll_area.wheelEvent = self.wheel_event\n",
    "        \n",
    "        # Zoom Controls\n",
    "        zoom_controls_layout = QHBoxLayout()\n",
    "        \n",
    "        self.zoom_in_button = QPushButton()\n",
    "        self.zoom_in_button.setIcon(self.style().standardIcon(QStyle.SP_ArrowUp))\n",
    "        self.zoom_in_button.setToolTip('Zoom In (+)')\n",
    "        self.zoom_in_button.clicked.connect(self.zoom_in)\n",
    "        \n",
    "        self.zoom_out_button = QPushButton()\n",
    "        self.zoom_out_button.setIcon(self.style().standardIcon(QStyle.SP_ArrowDown))\n",
    "        self.zoom_out_button.setToolTip('Zoom Out (-)')\n",
    "        self.zoom_out_button.clicked.connect(self.zoom_out)\n",
    "        \n",
    "        self.reset_button = QPushButton(\"100%\")\n",
    "        self.reset_button.setToolTip('Reset Zoom')\n",
    "        self.reset_button.clicked.connect(self.reset_zoom)\n",
    "        \n",
    "        self.zoom_label = QLabel(f'{self.current_zoom}%')\n",
    "        \n",
    "        zoom_controls_layout.addWidget(QLabel(\"Zoom:\"))\n",
    "        zoom_controls_layout.addWidget(self.zoom_out_button)\n",
    "        zoom_controls_layout.addWidget(self.zoom_label)\n",
    "        zoom_controls_layout.addWidget(self.zoom_in_button)\n",
    "        zoom_controls_layout.addWidget(self.reset_button)\n",
    "        \n",
    "        # Add slider for zoom control\n",
    "        self.zoom_slider = QSlider(Qt.Horizontal)\n",
    "        self.zoom_slider.setMinimum(self.min_zoom)\n",
    "        self.zoom_slider.setMaximum(self.max_zoom)\n",
    "        self.zoom_slider.setValue(self.current_zoom)\n",
    "        self.zoom_slider.setTickPosition(QSlider.TicksBelow)\n",
    "        self.zoom_slider.setTickInterval(25)\n",
    "        self.zoom_slider.valueChanged.connect(self.slider_zoom)\n",
    "        \n",
    "        # Add to image viewer layout\n",
    "        image_viewer_layout.addWidget(self.scroll_area)\n",
    "        image_viewer_layout.addLayout(zoom_controls_layout)\n",
    "        image_viewer_layout.addWidget(self.zoom_slider)\n",
    "        image_viewer_group.setLayout(image_viewer_layout)\n",
    "        \n",
    "        # Add groups to left panel\n",
    "        left_panel.addWidget(processing_options_group)\n",
    "        left_panel.addWidget(image_viewer_group)\n",
    "        \n",
    "        # Load a sample image\n",
    "        self.original_pixmap = self.create_sample_image(self.image_width, self.image_height)\n",
    "        self.image.setPixmap(self.original_pixmap)\n",
    "        self.update_image()\n",
    "\n",
    "        ################################# RIGHT PANEL #################################\n",
    "        right_panel = QVBoxLayout()\n",
    "        \n",
    "        # Timer Group\n",
    "        time_group = QGroupBox(\"Processing Time\")\n",
    "        time_layout = QVBoxLayout()\n",
    "        \n",
    "        # Timer controls\n",
    "        timer_controls = QHBoxLayout()\n",
    "        self.start_button = QPushButton('Start Time')\n",
    "        self.start_button.setIcon(self.style().standardIcon(QStyle.SP_MediaPlay))\n",
    "        self.start_button.clicked.connect(self.start_timer)\n",
    "        \n",
    "        self.end_button = QPushButton('End Time')\n",
    "        self.end_button.setIcon(self.style().standardIcon(QStyle.SP_MediaStop))\n",
    "        self.end_button.clicked.connect(self.end_timer)\n",
    "        self.end_button.setEnabled(False)  # Disabled until start is clicked\n",
    "        \n",
    "        timer_controls.addWidget(self.start_button)\n",
    "        timer_controls.addWidget(self.end_button)\n",
    "        \n",
    "        # Timer display\n",
    "        timer_display = QGridLayout()\n",
    "        timer_display.addWidget(QLabel(\"Start:\"), 0, 0)\n",
    "        self.start_label = QLabel('Not started')\n",
    "        timer_display.addWidget(self.start_label, 0, 1)\n",
    "        \n",
    "        timer_display.addWidget(QLabel(\"End:\"), 1, 0)\n",
    "        self.end_label = QLabel('Not ended')\n",
    "        timer_display.addWidget(self.end_label, 1, 1)\n",
    "        \n",
    "        timer_display.addWidget(QLabel(\"Elapsed:\"), 2, 0)\n",
    "        self.elapsed_time = QLabel('00:00:00.000')\n",
    "        self.elapsed_time.setStyleSheet(\"font-weight: bold;\")\n",
    "        timer_display.addWidget(self.elapsed_time, 2, 1)\n",
    "        \n",
    "        time_layout.addLayout(timer_controls)\n",
    "        time_layout.addLayout(timer_display)\n",
    "        time_group.setLayout(time_layout)\n",
    "        \n",
    "        # OCR Output Group\n",
    "        ocr_group = QGroupBox(\"OCR Output\")\n",
    "        ocr_layout = QVBoxLayout()\n",
    "        \n",
    "        # Text edit for OCR output\n",
    "        self.ocr_text_edit = QTextEdit()\n",
    "        self.ocr_text_edit.setReadOnly(False)\n",
    "        self.ocr_text_edit.setPlaceholderText(\"OCR text will appear here after processing a document\")\n",
    "        \n",
    "        # Add to OCR layout\n",
    "        ocr_layout.addWidget(self.ocr_text_edit)\n",
    "        ocr_group.setLayout(ocr_layout)\n",
    "        \n",
    "        # Speech Input Group\n",
    "        speech_group = QGroupBox(\"Speech Input\")\n",
    "        speech_layout = QVBoxLayout()\n",
    "        \n",
    "        # Recording controls\n",
    "        recording_controls = QHBoxLayout()\n",
    "        \n",
    "        self.record_button = QPushButton('Start Recording')\n",
    "        self.record_button.setIcon(self.style().standardIcon(QStyle.SP_DialogApplyButton))\n",
    "        self.record_button.clicked.connect(self.toggle_recording)\n",
    "        \n",
    "        self.insert_button = QPushButton('Insert at Cursor')\n",
    "        self.insert_button.setIcon(self.style().standardIcon(QStyle.SP_ArrowRight))\n",
    "        self.insert_button.clicked.connect(self.insert_at_cursor)\n",
    "        self.insert_button.setEnabled(False)\n",
    "        \n",
    "        self.replace_button = QPushButton('Replace Selected')\n",
    "        self.replace_button.setIcon(self.style().standardIcon(QStyle.SP_BrowserReload))\n",
    "        self.replace_button.clicked.connect(self.replace_selected)\n",
    "        self.replace_button.setEnabled(False)\n",
    "        \n",
    "        recording_controls.addWidget(self.record_button)\n",
    "        recording_controls.addWidget(self.insert_button)\n",
    "        recording_controls.addWidget(self.replace_button)\n",
    "        \n",
    "        # Save location display\n",
    "        save_location = QHBoxLayout()\n",
    "        self.directory_button = QPushButton('Change Location')\n",
    "        self.directory_button.clicked.connect(self.change_directory)\n",
    "        save_location.addWidget(self.directory_button)\n",
    "        \n",
    "        # Transcription display\n",
    "        self.transcription_label = QLabel(\"Transcription will appear here\")\n",
    "        self.transcription_label.setWordWrap(True)\n",
    "        self.transcription_label.setStyleSheet(\"background-color: #f0f0f0; padding: 5px; border: 1px solid #ddd;\")\n",
    "        \n",
    "        # Add to speech layout\n",
    "        speech_layout.addLayout(recording_controls)\n",
    "        speech_layout.addLayout(save_location)\n",
    "        speech_layout.addWidget(self.transcription_label)\n",
    "        speech_group.setLayout(speech_layout)\n",
    "        \n",
    "        # Add groups to right panel\n",
    "        right_panel.addWidget(time_group)\n",
    "        right_panel.addWidget(ocr_group, 1)  # Give OCR output more space\n",
    "        right_panel.addWidget(speech_group)\n",
    "        \n",
    "        ################################# ADD PANELS TO MAIN LAYOUT #################################\n",
    "        main_layout.addLayout(left_panel, 1)\n",
    "        main_layout.addLayout(right_panel, 1)\n",
    "        \n",
    "        # Show the main window\n",
    "        self.show()\n",
    "\n",
    "    def create_menu_bar(self):\n",
    "        \"\"\"Create menu bar with file and help options\"\"\"\n",
    "        menu_bar = self.menuBar()\n",
    "        \n",
    "        # File menu\n",
    "        file_menu = menu_bar.addMenu(\"File\")\n",
    "        \n",
    "        # Open action\n",
    "        open_action = QAction(\"Open Document\", self)\n",
    "        open_action.setShortcut(\"Ctrl+O\")\n",
    "        open_action.triggered.connect(self.load_document)\n",
    "        file_menu.addAction(open_action)\n",
    "        \n",
    "        # Save action\n",
    "        save_action = QAction(\"Save OCR Text\", self)\n",
    "        save_action.setShortcut(\"Ctrl+S\")\n",
    "        save_action.triggered.connect(self.save)\n",
    "        file_menu.addAction(save_action)\n",
    "        \n",
    "        file_menu.addSeparator()\n",
    "        \n",
    "        # Exit action\n",
    "        exit_action = QAction(\"Exit\", self)\n",
    "        exit_action.setShortcut(\"Ctrl+Q\")\n",
    "        exit_action.triggered.connect(self.close)\n",
    "        file_menu.addAction(exit_action)\n",
    "        \n",
    "        # Tools menu\n",
    "        tools_menu = menu_bar.addMenu(\"Tools\")\n",
    "        \n",
    "        # Recording action\n",
    "        record_action = QAction(\"Start Recording\", self)\n",
    "        record_action.triggered.connect(self.toggle_recording)\n",
    "        tools_menu.addAction(record_action)\n",
    "        \n",
    "        # Timer action\n",
    "        timer_action = QAction(\"Start Timer\", self)\n",
    "        timer_action.triggered.connect(self.start_timer)\n",
    "        tools_menu.addAction(timer_action)\n",
    "        \n",
    "        # Help menu\n",
    "        help_menu = menu_bar.addMenu(\"Help\")\n",
    "        \n",
    "        # About action\n",
    "        about_action = QAction(\"About MultiFOLD\", self)\n",
    "        about_action.triggered.connect(self.show_about)\n",
    "        help_menu.addAction(about_action)\n",
    "\n",
    "    def show_about(self):\n",
    "        \"\"\"Show information about the application\"\"\"\n",
    "        QMessageBox.about(self, \"About MultiFOLD\", \n",
    "                         \"MultiFOLD: Document Analysis and Correction Tool\\n\\n\"\n",
    "                         \"This application helps with document processing, OCR, and speech-to-text conversion.\\n\\n\"\n",
    "                         \"Use it to analyze documents, correct OCR errors, and track processing time.\")\n",
    "\n",
    "    def toggle_restormer(self, state):\n",
    "        \"\"\"Toggle Restormer image restoration on/off\"\"\"\n",
    "        if self.image_file is None:\n",
    "            if state == Qt.Checked:\n",
    "                self.statusBar.showMessage(\"No image loaded. Load an image first to apply Restormer.\")\n",
    "                self.restormer_toggle.setChecked(False)\n",
    "            return\n",
    "        \n",
    "        if state == Qt.Checked:\n",
    "            self.statusBar.showMessage(\"Applying Restormer image restoration...\")\n",
    "            # Store the current original image if not already stored\n",
    "            if not self.restormer_applied:\n",
    "                self.original_image = self.image_file.copy() if hasattr(self.image_file, 'copy') else self.image_file\n",
    "            \n",
    "            # Apply Restormer (placeholder implementation)\n",
    "            self.apply_restormer()\n",
    "            self.restormer_applied = True\n",
    "        else:\n",
    "            # Restore original image\n",
    "            if self.original_image is not None:\n",
    "                self.statusBar.showMessage(\"Restoring original image...\")\n",
    "                self.image_file = self.original_image\n",
    "                self.display_image(self.image_file)\n",
    "                self.restormer_applied = False\n",
    "\n",
    "    def apply_restormer(self):\n",
    "        \"\"\"Apply Restormer image restoration model to the current image\"\"\"\n",
    "        if self.image_file is None:\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            # Convert to numpy array if it's a PIL Image\n",
    "            if isinstance(self.image_file, Image.Image):\n",
    "                img_np = np.array(self.image_file)\n",
    "            else:\n",
    "                img_np = self.image_file\n",
    "                \n",
    "            # Ensure the image is in RGB format\n",
    "            if len(img_np.shape) == 2:  # If grayscale, convert to RGB\n",
    "                img_np = cv2.cvtColor(img_np, cv2.COLOR_GRAY2RGB)\n",
    "            elif len(img_np.shape) == 3 and img_np.shape[2] == 4:  # If RGBA, convert to RGB\n",
    "                img_np = cv2.cvtColor(img_np, cv2.COLOR_RGBA2RGB)\n",
    "            \n",
    "            # Define model parameters (based on the shared code)\n",
    "            task = 'Motion_Deblurring'  # You can make this configurable\n",
    "            parameters = {\n",
    "                'inp_channels': 3, \n",
    "                'out_channels': 3, \n",
    "                'dim': 48, \n",
    "                'num_blocks': [4, 6, 6, 8], \n",
    "                'num_refinement_blocks': 4, \n",
    "                'heads': [1, 2, 4, 8], \n",
    "                'ffn_expansion_factor': 2.66, \n",
    "                'bias': False, \n",
    "                'LayerNorm_type': 'WithBias', \n",
    "                'dual_pixel_task': False\n",
    "            }\n",
    "            \n",
    "            # Adjust parameters based on the task\n",
    "            if task == 'Real_Denoising':\n",
    "                parameters['LayerNorm_type'] = 'BiasFree'\n",
    "                weights_path = 'pretrained_models/real_denoising.pth'\n",
    "            elif task == 'Single_Image_Defocus_Deblurring':\n",
    "                weights_path = 'pretrained_models/single_image_defocus_deblurring.pth'\n",
    "            elif task == 'Motion_Deblurring':\n",
    "                weights_path = 'pretrained_models/motion_deblurring.pth'\n",
    "            elif task == 'Deraining':\n",
    "                weights_path = 'pretrained_models/deraining.pth'\n",
    "            \n",
    "            # Load the model\n",
    "            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            model = Restormer(**parameters)\n",
    "            model.to(device)\n",
    "            \n",
    "            # Load weights\n",
    "            checkpoint = torch.load(weights_path, map_location=device)\n",
    "            model.load_state_dict(checkpoint['params'])\n",
    "            model.eval()\n",
    "            \n",
    "            # Prepare input tensor\n",
    "            img_multiple_of = 8\n",
    "            input_ = torch.from_numpy(img_np).float().div(255.).permute(2, 0, 1).unsqueeze(0).to(device)\n",
    "            \n",
    "            # Pad the input if not multiple of 8\n",
    "            h, w = input_.shape[2], input_.shape[3]\n",
    "            H = ((h + img_multiple_of) // img_multiple_of) * img_multiple_of\n",
    "            W = ((w + img_multiple_of) // img_multiple_of) * img_multiple_of\n",
    "            padh = H - h if h % img_multiple_of != 0 else 0\n",
    "            padw = W - w if w % img_multiple_of != 0 else 0\n",
    "            input_ = F.pad(input_, (0, padw, 0, padh), 'reflect')\n",
    "            \n",
    "            # Process with model\n",
    "            with torch.no_grad():\n",
    "                restored = model(input_)\n",
    "                restored = torch.clamp(restored, 0, 1)\n",
    "                \n",
    "                # Unpad the output\n",
    "                restored = restored[:, :, :h, :w]\n",
    "                \n",
    "                # Convert to numpy\n",
    "                restored = restored.permute(0, 2, 3, 1).cpu().detach().numpy()\n",
    "                restored = img_as_ubyte(restored[0])\n",
    "            \n",
    "            # Convert back to PIL Image and update display\n",
    "            restored_pil = Image.fromarray(restored)\n",
    "            self.image_file = restored_pil\n",
    "            \n",
    "            # Display the restored image\n",
    "            self.display_image(restored_pil)\n",
    "            \n",
    "            self.statusBar.showMessage(f\"Restormer {task} applied successfully\")\n",
    "            \n",
    "        except ImportError as e:\n",
    "            self.statusBar.showMessage(f\"Error: Missing dependencies - {str(e)}\")\n",
    "            QMessageBox.warning(self, \"Restormer Error\", \n",
    "                            f\"Missing dependencies: {str(e)}\\nPlease install required packages.\")\n",
    "            self.restormer_toggle.setChecked(False)\n",
    "        except FileNotFoundError as e:\n",
    "            self.statusBar.showMessage(\"Error: Restormer model weights not found\")\n",
    "            QMessageBox.warning(self, \"Restormer Error\", \n",
    "                            f\"Model weights not found: {str(e)}\\nPlease download the model files.\")\n",
    "            self.restormer_toggle.setChecked(False)\n",
    "        except Exception as e:\n",
    "            self.statusBar.showMessage(f\"Error applying Restormer: {str(e)}\")\n",
    "            QMessageBox.warning(self, \"Restormer Error\", f\"Could not apply Restormer: {str(e)}\")\n",
    "            self.restormer_toggle.setChecked(False)\n",
    "\n",
    "    # def apply_restormer(self):\n",
    "    #     \"\"\"Apply Restormer image restoration model to the current image\"\"\"\n",
    "    #     # This is a placeholder implementation since we don't have actual Restormer integration\n",
    "    #     # In a real implementation, this would call the Restormer model\n",
    "        \n",
    "    #     if self.image_file is None:\n",
    "    #         return\n",
    "        \n",
    "    #     try:\n",
    "    #         # Convert to numpy array if it's a PIL Image\n",
    "    #         if isinstance(self.image_file, Image.Image):\n",
    "    #             img_np = np.array(self.image_file)\n",
    "    #         else:\n",
    "    #             img_np = self.image_file\n",
    "                \n",
    "    #         # Placeholder Restormer effect - just apply simple image enhancement\n",
    "    #         # In reality, you would call the actual Restormer model here\n",
    "            \n",
    "    #         # Convert to grayscale if it's color\n",
    "    #         if len(img_np.shape) == 3 and img_np.shape[2] >= 3:\n",
    "    #             gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)\n",
    "    #         else:\n",
    "    #             gray = img_np\n",
    "                \n",
    "    #         # Apply simple enhancement (adaptive histogram equalization)\n",
    "    #         clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    #         enhanced = clahe.apply(gray)\n",
    "            \n",
    "    #         # Convert back to RGB for display\n",
    "    #         enhanced_rgb = cv2.cvtColor(enhanced, cv2.COLOR_GRAY2RGB)\n",
    "            \n",
    "    #         # Convert back to PIL Image\n",
    "    #         enhanced_pil = Image.fromarray(enhanced_rgb)\n",
    "    #         self.image_file = enhanced_pil\n",
    "            \n",
    "    #         # Display the enhanced image\n",
    "    #         self.display_image(enhanced_pil)\n",
    "            \n",
    "    #         self.statusBar.showMessage(\"Restormer applied (simulated enhancement)\")\n",
    "            \n",
    "    #     except Exception as e:\n",
    "    #         self.statusBar.showMessage(f\"Error applying Restormer: {str(e)}\")\n",
    "    #         QMessageBox.warning(self, \"Restormer Error\", f\"Could not apply Restormer: {str(e)}\")\n",
    "    #         self.restormer_toggle.setChecked(False)\n",
    "\n",
    "    ############### Document Processing Methods ###############\n",
    "    def remove_extra_newlines(self, text):\n",
    "        cleaned_text = re.sub(r'\\n+', '\\n', text).strip()\n",
    "        return cleaned_text\n",
    "\n",
    "    def load_document(self):\n",
    "        # Open file dialog to load an image or document\n",
    "        options = QFileDialog.Options()\n",
    "        file, _ = QFileDialog.getOpenFileName(self, \"Open Document\", \"\", \n",
    "                                             \"All Files (*);;Image Files (*.png; *.jpg; *.jpeg);;Word Documents (*.docx);;PDF Files (*.pdf)\", \n",
    "                                             options=options)\n",
    "\n",
    "        if file:\n",
    "            self.statusBar.showMessage(f\"Processing document: {os.path.basename(file)}\")\n",
    "            # Reset Restormer toggle when loading a new document\n",
    "            self.restormer_toggle.setChecked(False)\n",
    "            self.restormer_applied = False\n",
    "            self.original_image = None\n",
    "            \n",
    "            self.process_document(file)\n",
    "            self.statusBar.showMessage(f\"Document processed: {os.path.basename(file)}\")\n",
    "\n",
    "    def process_document(self, file):\n",
    "        if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            # Process as image file\n",
    "            self.image_file = Image.open(file)\n",
    "            self.display_image(self.image_file)\n",
    "            ocr_text = pytesseract.image_to_string(self.image_file)\n",
    "            \n",
    "            ocr_text = self.remove_extra_newlines(ocr_text)\n",
    "            self.ocr_text_edit.setText(ocr_text)\n",
    "            \n",
    "        elif file.lower().endswith('.docx'):\n",
    "            # Process as Word document\n",
    "            self.process_word_document(file)\n",
    "            \n",
    "        elif file.lower().endswith('.pdf'):\n",
    "            # Process as PDF document\n",
    "            self.process_pdf_document(file)\n",
    "\n",
    "    def process_word_document(self, file):\n",
    "        doc = Document(file)\n",
    "        full_text = ''\n",
    "        for para in doc.paragraphs:\n",
    "            full_text += para.text + '\\n'\n",
    "\n",
    "        full_text = self.remove_extra_newlines(full_text)\n",
    "        self.ocr_text_edit.setText(full_text)\n",
    "        \n",
    "        # Create a placeholder image for the document\n",
    "        self.create_document_preview(\"Word Document\")\n",
    "\n",
    "    def process_pdf_document(self, file):\n",
    "        # Convert PDF pages to images\n",
    "        pages = convert_from_path(file, 600)\n",
    "        if pages:\n",
    "            # Use the first page for OCR and display\n",
    "            self.image_file = pages[0]\n",
    "            self.display_image(self.image_file)\n",
    "\n",
    "            # Perform OCR on the first page image\n",
    "            ocr_text = pytesseract.image_to_string(self.image_file)\n",
    "            \n",
    "            if ocr_text.strip() == \"\":\n",
    "                ocr_text = \"No text detected in this document.\"\n",
    "\n",
    "            ocr_text = self.remove_extra_newlines(ocr_text)\n",
    "            self.ocr_text_edit.setText(ocr_text)\n",
    "\n",
    "    def save(self):\n",
    "        options = QFileDialog.Options()\n",
    "        file_name, _ = QFileDialog.getSaveFileName(self, \"Save OCR Text\", \"\", \n",
    "                                                 \"Text Files (*.txt);;All Files (*)\", \n",
    "                                                 options=options)\n",
    "\n",
    "        if file_name:\n",
    "            try:\n",
    "                text = self.ocr_text_edit.toPlainText()\n",
    "                \n",
    "                # Ensure file has .txt extension\n",
    "                if not file_name.lower().endswith('.txt'):\n",
    "                    file_name += '.txt'\n",
    "                    \n",
    "                with open(file_name, 'w') as f:\n",
    "                    f.write(text)\n",
    "                    \n",
    "                self.statusBar.showMessage(f\"Text saved to {os.path.basename(file_name)}\")\n",
    "            except Exception as e:\n",
    "                self.statusBar.showMessage(f\"Error saving file: {str(e)}\")\n",
    "                QMessageBox.critical(self, \"Save Error\", f\"Could not save file: {str(e)}\")\n",
    "\n",
    "    ############### Image Display Methods ###############\n",
    "    def display_image(self, image):\n",
    "        \"\"\"Display image in the QLabel\"\"\"\n",
    "        # Convert PIL Image to QPixmap\n",
    "        self.original_pixmap = self.pil_image_to_pixmap(image)\n",
    "        self.image.setPixmap(self.original_pixmap)\n",
    "        self.update_image()\n",
    "\n",
    "    def create_document_preview(self, doc_type):\n",
    "        \"\"\"Create a placeholder image for non-image documents\"\"\"\n",
    "        # Create a blank QImage\n",
    "        qimage = QImage(800, 600, QImage.Format_RGB32)\n",
    "        qimage.fill(Qt.white)\n",
    "        \n",
    "        # Create a QPainter to draw on the image\n",
    "        painter = QPainter(qimage)\n",
    "        painter.setPen(Qt.black)\n",
    "        painter.setFont(QFont(\"Arial\", 20))\n",
    "        \n",
    "        # Draw text in the center\n",
    "        painter.drawText(qimage.rect(), Qt.AlignCenter, f\"{doc_type}\\nProcessed Successfully\")\n",
    "        \n",
    "        # Draw a border\n",
    "        painter.drawRect(10, 10, qimage.width() - 20, qimage.height() - 20)\n",
    "        painter.end()\n",
    "        \n",
    "        # Convert to QPixmap and display\n",
    "        self.original_pixmap = QPixmap.fromImage(qimage)\n",
    "        self.image.setPixmap(self.original_pixmap)\n",
    "        self.update_image()\n",
    "\n",
    "    def pil_image_to_pixmap(self, pil_image):\n",
    "        \"\"\"Convert a PIL Image to QPixmap\"\"\"\n",
    "        # Convert PIL Image to RGB if it's not already\n",
    "        if pil_image.mode != \"RGB\":\n",
    "            pil_image = pil_image.convert(\"RGB\")\n",
    "            \n",
    "        image_data = pil_image.tobytes(\"raw\", \"RGB\")\n",
    "        q_image = QImage(image_data, pil_image.width, pil_image.height, pil_image.width * 3, QImage.Format_RGB888)\n",
    "        return QPixmap.fromImage(q_image)\n",
    "\n",
    "    def create_sample_image(self, width, height):\n",
    "        \"\"\"Create a sample image if no image is loaded\"\"\"\n",
    "        # Create a blank image with a grid pattern\n",
    "        image = QImage(width, height, QImage.Format_RGB32)\n",
    "        image.fill(Qt.white)\n",
    "        \n",
    "        # Create a QPainter to draw on the image\n",
    "        painter = QPainter(image)\n",
    "        painter.setPen(Qt.lightGray)\n",
    "        \n",
    "        # Draw a grid\n",
    "        for x in range(0, width, 50):\n",
    "            painter.drawLine(x, 0, x, height)\n",
    "        \n",
    "        for y in range(0, height, 50):\n",
    "            painter.drawLine(0, y, width, y)\n",
    "        \n",
    "        # Draw text in the center\n",
    "        painter.setPen(Qt.black)\n",
    "        painter.setFont(QFont(\"Arial\", 18))\n",
    "        painter.drawText(image.rect(), Qt.AlignCenter, \"MultiFOLD\\nLoad a document to begin\")\n",
    "        \n",
    "        painter.end()\n",
    "        \n",
    "        # Create a pixmap from the image\n",
    "        return QPixmap.fromImage(image)\n",
    "\n",
    "    ############### Zoom Control Methods ###############\n",
    "    def update_image(self):\n",
    "        \"\"\"Update the image with the current zoom level\"\"\"\n",
    "        # Calculate new dimensions\n",
    "        new_width = int((self.original_pixmap.width() * self.current_zoom) / 100)\n",
    "        new_height = int((self.original_pixmap.height() * self.current_zoom) / 100)\n",
    "        \n",
    "        # Set fixed size for the label based on zoomed dimensions\n",
    "        self.image.setFixedSize(new_width, new_height)\n",
    "        \n",
    "        # Set the pixmap\n",
    "        self.image.setPixmap(self.original_pixmap)\n",
    "        \n",
    "        # Update zoom label\n",
    "        self.zoom_label.setText(f'{self.current_zoom}%')\n",
    "        \n",
    "        # Update slider without triggering valueChanged signal\n",
    "        self.zoom_slider.blockSignals(True)\n",
    "        self.zoom_slider.setValue(self.current_zoom)\n",
    "        self.zoom_slider.blockSignals(False)\n",
    "    \n",
    "    def zoom_in(self):\n",
    "        \"\"\"Increase zoom level\"\"\"\n",
    "        if self.current_zoom < self.max_zoom:\n",
    "            self.current_zoom += self.zoom_step\n",
    "            self.update_image()\n",
    "    \n",
    "    def zoom_out(self):\n",
    "        \"\"\"Decrease zoom level, but not below minimum\"\"\"\n",
    "        if self.current_zoom > self.min_zoom:\n",
    "            self.current_zoom -= self.zoom_step\n",
    "            self.update_image()\n",
    "    \n",
    "    def reset_zoom(self):\n",
    "        \"\"\"Reset zoom to 100%\"\"\"\n",
    "        self.current_zoom = 100\n",
    "        self.update_image()\n",
    "    \n",
    "    def slider_zoom(self, value):\n",
    "        \"\"\"Handle zoom from slider\"\"\"\n",
    "        self.current_zoom = value\n",
    "        self.update_image()\n",
    "    \n",
    "    def wheel_event(self, event):\n",
    "        \"\"\"Handle mouse wheel events for zooming\"\"\"\n",
    "        if event.modifiers() & Qt.ControlModifier:\n",
    "            # Zoom with Ctrl+Wheel\n",
    "            delta = event.angleDelta().y()\n",
    "            if delta > 0:\n",
    "                self.zoom_in()\n",
    "            else:\n",
    "                self.zoom_out()\n",
    "            event.accept()\n",
    "        else:\n",
    "            # Default scroll behavior\n",
    "            QScrollArea.wheelEvent(self.scroll_area, event)\n",
    "    \n",
    "    def keyPressEvent(self, event):\n",
    "        \"\"\"Handle keyboard shortcuts for zooming\"\"\"\n",
    "        if event.key() == Qt.Key_Plus or event.key() == Qt.Key_Equal:\n",
    "            self.zoom_in()\n",
    "        elif event.key() == Qt.Key_Minus:\n",
    "            self.zoom_out()\n",
    "        elif event.key() == Qt.Key_0:\n",
    "            self.reset_zoom()\n",
    "        else:\n",
    "            super().keyPressEvent(event)\n",
    "\n",
    "    ############### Timer Methods ###############\n",
    "    def start_timer(self):\n",
    "        self.start_time = QDateTime.currentDateTime()\n",
    "        self.start_label.setText(f'{self.start_time.toString(\"hh:mm:ss.zzz\")}')\n",
    "        self.start_button.setEnabled(False)\n",
    "        self.end_button.setEnabled(True)\n",
    "        self.elapsed_time.setText('00:00:00.000')\n",
    "        self.statusBar.showMessage(\"Timer started\")\n",
    "    \n",
    "    def end_timer(self):\n",
    "        if self.start_time:\n",
    "            self.end_time = QDateTime.currentDateTime()\n",
    "            self.end_label.setText(f'{self.end_time.toString(\"hh:mm:ss.zzz\")}')\n",
    "            self.calculate_difference()\n",
    "            self.start_button.setEnabled(True)\n",
    "            self.end_button.setEnabled(False)\n",
    "            self.statusBar.showMessage(\"Timer stopped\")\n",
    "    \n",
    "    def calculate_difference(self):\n",
    "        if self.start_time and self.end_time:\n",
    "            # Calculate time difference in milliseconds\n",
    "            milliseconds = self.start_time.msecsTo(self.end_time)\n",
    "            \n",
    "            # Format the time difference in hh:mm:ss.msms format\n",
    "            hours = milliseconds // 3600000\n",
    "            minutes = (milliseconds % 3600000) // 60000\n",
    "            seconds = (milliseconds % 60000) // 1000\n",
    "            ms = milliseconds % 1000\n",
    "            \n",
    "            formatted_time = f\"{hours:02d}:{minutes:02d}:{seconds:02d}.{ms:03d}\"\n",
    "            # Display result in the label\n",
    "            self.elapsed_time.setText(f'{formatted_time}')\n",
    "\n",
    "    ############### Speech Recording Methods ###############\n",
    "    def get_timestamped_filename(self):\n",
    "        \"\"\"Generate a filename with current timestamp\"\"\"\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        audio_file = os.path.join(self.recordings_dir, f\"audio_{timestamp}.wav\")\n",
    "        return audio_file, timestamp\n",
    "    \n",
    "    def toggle_recording(self):\n",
    "        if self.recording_thread is None:\n",
    "            # Start recording with timestamped filename\n",
    "            audio_file, self.current_timestamp = self.get_timestamped_filename()\n",
    "            self.current_audio_file = audio_file\n",
    "            \n",
    "            self.statusBar.showMessage(f\"Recording... (File: audio_{self.current_timestamp}.wav)\")\n",
    "            self.record_button.setText(\"Stop Recording\")\n",
    "            self.record_button.setIcon(self.style().standardIcon(QStyle.SP_MediaStop))\n",
    "            self.recording_thread = RecordingThread(audio_file)\n",
    "            self.recording_thread.finished.connect(self.on_transcription_finished)\n",
    "            self.recording_thread.start()\n",
    "        else:\n",
    "            # Stop recording\n",
    "            self.statusBar.showMessage(\"Processing speech...\")\n",
    "            self.record_button.setText(\"Start Recording\")\n",
    "            self.record_button.setIcon(self.style().standardIcon(QStyle.SP_DialogApplyButton))\n",
    "            self.recording_thread.stop()\n",
    "            self.recording_thread = None\n",
    "    \n",
    "    def on_transcription_finished(self, text, audio_file):\n",
    "        \"\"\"Handle completed transcription and save to file\"\"\"\n",
    "        self.statusBar.showMessage(f\"Transcription complete: {os.path.basename(audio_file)}\")\n",
    "        self.last_transcription = text\n",
    "        self.transcription_label.setText(text)\n",
    "        self.insert_button.setEnabled(True)\n",
    "        self.replace_button.setEnabled(True)\n",
    "        \n",
    "        # Save transcription to a JSON file with same timestamp\n",
    "        timestamp = os.path.basename(audio_file).replace(\"audio_\", \"\").replace(\".wav\", \"\")\n",
    "        transcription_file = os.path.join(self.transcriptions_dir, f\"transcription_{timestamp}.json\")\n",
    "        \n",
    "        transcription_data = {\n",
    "            \"timestamp\": timestamp,\n",
    "            \"audio_file\": audio_file,\n",
    "            \"transcription\": text,\n",
    "            \"date\": datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "        \n",
    "        with open(transcription_file, 'w') as f:\n",
    "            json.dump(transcription_data, f, indent=4)\n",
    "            \n",
    "        self.statusBar.showMessage(f\"Saved: {os.path.basename(audio_file)} and {os.path.basename(transcription_file)}\")\n",
    "    \n",
    "    def insert_at_cursor(self):\n",
    "        if self.last_transcription:\n",
    "            cursor = self.ocr_text_edit.textCursor()\n",
    "            cursor.insertText(self.last_transcription)\n",
    "            self.statusBar.showMessage(\"Text inserted at cursor position\")\n",
    "    \n",
    "    def replace_selected(self):\n",
    "        if self.last_transcription:\n",
    "            cursor = self.ocr_text_edit.textCursor()\n",
    "            if cursor.hasSelection():\n",
    "                cursor.insertText(self.last_transcription)\n",
    "                self.statusBar.showMessage(\"Selected text replaced\")\n",
    "            else:\n",
    "                self.statusBar.showMessage(\"No text selected to replace\")\n",
    "    \n",
    "    def change_directory(self):\n",
    "        \"\"\"Change the directory where recordings and transcriptions are saved\"\"\"\n",
    "        parent_dir = QFileDialog.getExistingDirectory(self, \"Select Directory\")\n",
    "        if parent_dir:\n",
    "            self.recordings_dir = os.path.join(parent_dir, \"recordings\")\n",
    "            self.transcriptions_dir = os.path.join(parent_dir, \"transcriptions\")\n",
    "            \n",
    "            # Create directories if they don't exist\n",
    "            for directory in [self.recordings_dir, self.transcriptions_dir]:\n",
    "                if not os.path.exists(directory):\n",
    "                    os.makedirs(directory)\n",
    "                    \n",
    "            self.statusBar.showMessage(f\"Changed save location to {os.path.abspath(self.recordings_dir)}\")\n",
    "    \n",
    "    def closeEvent(self, event):\n",
    "        # Ask user for confirmation before closing\n",
    "        reply = QMessageBox.question(self, 'Exit Confirmation',\n",
    "                                    'Are you sure you want to exit?',\n",
    "                                    QMessageBox.Yes | QMessageBox.No,\n",
    "                                    QMessageBox.No)\n",
    "\n",
    "        if reply == QMessageBox.Yes:\n",
    "            # If recording is active, stop it\n",
    "            if self.recording_thread is not None:\n",
    "                self.recording_thread.stop()\n",
    "                self.recording_thread = None\n",
    "            event.accept()\n",
    "        else:\n",
    "            event.ignore()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Make sure the application looks good on high DPI displays\n",
    "    QApplication.setAttribute(Qt.AA_EnableHighDpiScaling, True)\n",
    "    QApplication.setAttribute(Qt.AA_UseHighDpiPixmaps, True)\n",
    "    \n",
    "    app = QApplication(sys.argv)\n",
    "    \n",
    "    # Set application style for a more modern look\n",
    "    app.setStyle(\"Fusion\")\n",
    "    \n",
    "    # Apply a palette to get a consistent look across platforms\n",
    "    palette = QPalette()\n",
    "    palette.setColor(QPalette.Window, QColor(240, 240, 240))\n",
    "    palette.setColor(QPalette.WindowText, QColor(0, 0, 0))\n",
    "    palette.setColor(QPalette.Base, QColor(255, 255, 255))\n",
    "    palette.setColor(QPalette.AlternateBase, QColor(230, 230, 230))\n",
    "    palette.setColor(QPalette.ToolTipBase, QColor(255, 255, 220))\n",
    "    palette.setColor(QPalette.ToolTipText, QColor(0, 0, 0))\n",
    "    palette.setColor(QPalette.Text, QColor(0, 0, 0))\n",
    "    palette.setColor(QPalette.Button, QColor(240, 240, 240))\n",
    "    palette.setColor(QPalette.ButtonText, QColor(0, 0, 0))\n",
    "    palette.setColor(QPalette.BrightText, QColor(255, 0, 0))\n",
    "    palette.setColor(QPalette.Highlight, QColor(42, 130, 218))\n",
    "    palette.setColor(QPalette.HighlightedText, QColor(255, 255, 255))\n",
    "    app.setPalette(palette)\n",
    "    \n",
    "    window = MultiFOLD()\n",
    "    window.show()\n",
    "    sys.exit(app.exec_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
